{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31c01ab2",
   "metadata": {
    "papermill": {
     "duration": 0.005524,
     "end_time": "2023-05-25T13:15:37.747012",
     "exception": false,
     "start_time": "2023-05-25T13:15:37.741488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The program is not ready yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47681871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:15:37.759362Z",
     "iopub.status.busy": "2023-05-25T13:15:37.758960Z",
     "iopub.status.idle": "2023-05-25T13:21:37.934232Z",
     "shell.execute_reply": "2023-05-25T13:21:37.933028Z"
    },
    "papermill": {
     "duration": 360.184471,
     "end_time": "2023-05-25T13:21:37.936752",
     "exception": false,
     "start_time": "2023-05-25T13:15:37.752281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mmcv\r\n",
      "  Downloading mmcv-2.0.0.tar.gz (473 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.2/473.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting addict (from mmcv)\r\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
      "Collecting mmengine>=0.2.0 (from mmcv)\r\n",
      "  Downloading mmengine-0.7.3-py3-none-any.whl (372 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.1/372.1 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmcv) (1.23.5)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv) (21.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv) (9.5.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv) (5.4.1)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv) (0.33.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.2.0->mmcv) (3.6.3)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.2.0->mmcv) (13.3.5)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.2.0->mmcv) (2.3.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.2.0->mmcv) (4.5.4.60)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mmcv) (3.0.9)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv) (2.0.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv) (1.0.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv) (4.39.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv) (1.4.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv) (2.8.2)\r\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.2.0->mmcv) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.2.0->mmcv) (2.15.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->mmengine>=0.2.0->mmcv) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.2.0->mmcv) (1.16.0)\r\n",
      "Building wheels for collected packages: mmcv\r\n",
      "  Building wheel for mmcv (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mmcv: filename=mmcv-2.0.0-cp310-cp310-linux_x86_64.whl size=1359221 sha256=6f4c4a368c45bab6caeffbfb0c65ab2cc783952f593d2fe91f86adb82e4a7b5a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/1b/83/aca08aea56449d2284a1025b6e7a762dec954827816a38109d\r\n",
      "Successfully built mmcv\r\n",
      "Installing collected packages: addict, mmengine, mmcv\r\n",
      "Successfully installed addict-2.4.0 mmcv-2.0.0 mmengine-0.7.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "766c3ff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:21:37.960705Z",
     "iopub.status.busy": "2023-05-25T13:21:37.960311Z",
     "iopub.status.idle": "2023-05-25T13:22:12.827573Z",
     "shell.execute_reply": "2023-05-25T13:22:12.826331Z"
    },
    "papermill": {
     "duration": 34.882501,
     "end_time": "2023-05-25T13:22:12.830141",
     "exception": false,
     "start_time": "2023-05-25T13:21:37.947640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mmocr\r\n",
      "  Downloading mmocr-1.0.0-py2.py3-none-any.whl (618 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.1/618.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: imgaug in /opt/conda/lib/python3.10/site-packages (from mmocr) (0.4.0)\r\n",
      "Collecting lmdb (from mmocr)\r\n",
      "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmocr) (3.6.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmocr) (1.23.5)\r\n",
      "Requirement already satisfied: opencv-python!=4.5.5.*,>=4.2.0.32 in /opt/conda/lib/python3.10/site-packages (from mmocr) (4.5.4.60)\r\n",
      "Requirement already satisfied: pyclipper in /opt/conda/lib/python3.10/site-packages (from mmocr) (1.3.0.post4)\r\n",
      "Collecting pycocotools (from mmocr)\r\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: rapidfuzz>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from mmocr) (3.0.0)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from mmocr) (0.20.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from imgaug->mmocr) (1.16.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from imgaug->mmocr) (1.10.1)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from imgaug->mmocr) (9.5.0)\r\n",
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from imgaug->mmocr) (2.28.1)\r\n",
      "Requirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from imgaug->mmocr) (1.8.5.post1)\r\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->mmocr) (3.1)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image->mmocr) (2023.4.12)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->mmocr) (1.4.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from scikit-image->mmocr) (21.3)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->mmocr) (0.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmocr) (1.0.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmocr) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmocr) (4.39.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmocr) (1.4.4)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmocr) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmocr) (2.8.2)\r\n",
      "Building wheels for collected packages: pycocotools\r\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl size=102203 sha256=28fb6a2d992a7ad67ad32bff160308987226839154854d20b5ae715754260e58\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/58/e6/f9/f87c8f8be098b51b616871315318329cae12cdb618f4caac93\r\n",
      "Successfully built pycocotools\r\n",
      "Installing collected packages: lmdb, pycocotools, mmocr\r\n",
      "Successfully installed lmdb-1.4.1 mmocr-1.0.0 pycocotools-2.0.6\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mmocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70fbaa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:22:12.858957Z",
     "iopub.status.busy": "2023-05-25T13:22:12.858053Z",
     "iopub.status.idle": "2023-05-25T13:22:25.846391Z",
     "shell.execute_reply": "2023-05-25T13:22:25.844952Z"
    },
    "papermill": {
     "duration": 13.00557,
     "end_time": "2023-05-25T13:22:25.848981",
     "exception": false,
     "start_time": "2023-05-25T13:22:12.843411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mmdet\r\n",
      "  Downloading mmdet-3.0.0-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmdet) (3.6.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmdet) (1.23.5)\r\n",
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.10/site-packages (from mmdet) (2.0.6)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from mmdet) (1.10.1)\r\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.10/site-packages (from mmdet) (1.8.5.post1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from mmdet) (1.16.0)\r\n",
      "Collecting terminaltables (from mmdet)\r\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (1.0.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (4.39.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (2.8.2)\r\n",
      "Installing collected packages: terminaltables, mmdet\r\n",
      "Successfully installed mmdet-3.0.0 terminaltables-3.1.10\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mmdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aba9654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:22:25.878794Z",
     "iopub.status.busy": "2023-05-25T13:22:25.878374Z",
     "iopub.status.idle": "2023-05-25T13:22:25.883271Z",
     "shell.execute_reply": "2023-05-25T13:22:25.882221Z"
    },
    "papermill": {
     "duration": 0.022563,
     "end_time": "2023-05-25T13:22:25.885421",
     "exception": false,
     "start_time": "2023-05-25T13:22:25.862858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66186b17",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-25T13:22:25.914642Z",
     "iopub.status.busy": "2023-05-25T13:22:25.914254Z",
     "iopub.status.idle": "2023-05-25T13:22:32.201785Z",
     "shell.execute_reply": "2023-05-25T13:22:32.200088Z"
    },
    "papermill": {
     "duration": 6.305352,
     "end_time": "2023-05-25T13:22:32.204723",
     "exception": false,
     "start_time": "2023-05-25T13:22:25.899371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#from sklearn.metrics import f1_score, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "import torchvision\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import mmocr\n",
    "from mmocr.models import textrecog\n",
    "#help(textrecog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e4d1a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:22:32.234270Z",
     "iopub.status.busy": "2023-05-25T13:22:32.233868Z",
     "iopub.status.idle": "2023-05-25T13:22:32.239814Z",
     "shell.execute_reply": "2023-05-25T13:22:32.238012Z"
    },
    "papermill": {
     "duration": 0.023778,
     "end_time": "2023-05-25T13:22:32.242844",
     "exception": false,
     "start_time": "2023-05-25T13:22:32.219066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#with open('mmocr.joblib','wb') as f:\n",
    "#    joblib.dump(mmocr,f)\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8da33e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:22:32.275029Z",
     "iopub.status.busy": "2023-05-25T13:22:32.274647Z",
     "iopub.status.idle": "2023-05-25T13:22:32.280324Z",
     "shell.execute_reply": "2023-05-25T13:22:32.278991Z"
    },
    "papermill": {
     "duration": 0.02377,
     "end_time": "2023-05-25T13:22:32.282698",
     "exception": false,
     "start_time": "2023-05-25T13:22:32.258928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_convrt(img):\n",
    "    img = img.clone().cpu().numpy()\n",
    "    img = img.transpose(1,2,0)\n",
    "    std = [0.5,0.5,0.5]\n",
    "    mean = [0.5,0.5,0.5]\n",
    "    img = img*std + mean\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f5a7b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:22:32.312868Z",
     "iopub.status.busy": "2023-05-25T13:22:32.312413Z",
     "iopub.status.idle": "2023-05-25T13:22:32.336546Z",
     "shell.execute_reply": "2023-05-25T13:22:32.335408Z"
    },
    "papermill": {
     "duration": 0.042331,
     "end_time": "2023-05-25T13:22:32.338732",
     "exception": false,
     "start_time": "2023-05-25T13:22:32.296401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Функция для воссоздания маски изображения из файла json\n",
    "def interesting(path,dimensions):\n",
    "    def typization(string):\n",
    "        if string=='chart_title':\n",
    "            return (1,1,1)\n",
    "        elif string=='axis_title':\n",
    "            return (2,2,2)\n",
    "        elif string=='tick_label':\n",
    "            return (3,3,3)\n",
    "        elif string=='plot-bb':\n",
    "            return (4,4,4)\n",
    "        elif string=='axes':\n",
    "            return (5,5,5)\n",
    "        elif string==\"bars\":\n",
    "            return (6,6,6)\n",
    "        elif string==\"boxplots\":\n",
    "            return (7,7,7)\n",
    "        elif string==\"dot points\":\n",
    "            return (8,8,8)\n",
    "        elif string==\"lines\":\n",
    "            return (9,9,9)\n",
    "        elif string==\"scatter points\":\n",
    "            return (10,10,10)\n",
    "#    creator = np.array(dimensions[1]*[dimensions[2]*[0]])\n",
    "    creator = np.zeros((dimensions[1], dimensions[2]), dtype=np.uint8)\n",
    "    creator = cv2.cvtColor(creator, cv2.COLOR_GRAY2BGR)\n",
    "    print('img: ', dimensions,'\\n')\n",
    "    s=\"\"\n",
    "    with open(path) as f:\n",
    "        s=f.read()\n",
    "    gen=json.loads(s)\n",
    "    gen2=gen['plot-bb']\n",
    "    cv2.fillPoly(creator, [np.array([[(gen2['x0']+gen2['width'],gen2['y0'])],[(gen2['x0'],gen2['y0'])],[(gen2['x0'],gen2['y0']+gen2['height'])],[(gen2['x0']+gen2['width'],gen2['y0']+gen2['height'])]],dtype=np.int32)], typization('plot-bb'))\n",
    "    for i in range(len(gen['text'])):\n",
    "        if len(gen['text'][i]['polygon'])!=0:\n",
    "            gen1=gen['text'][i]['polygon']\n",
    "            cv2.fillPoly(creator, [np.array([[(gen1['x0'],gen1['y0'])],[(gen1['x1'],gen1['y1'])],[(gen1['x2'],gen1['y2'])],[(gen1['x3'],gen1['y3'])]],dtype=np.int32)], typization(gen['text'][i]['role']))\n",
    "    axe=gen['axes']\n",
    "    axex=axe['x-axis']['ticks']\n",
    "    axey=axe['y-axis']['ticks']\n",
    "    for i in range(len(axex)):\n",
    "        cv2.fillPoly(creator, [np.array([[(axex[i]['tick_pt']['x'],axex[i]['tick_pt']['y'])],[(axex[i]['tick_pt']['x'],axex[i]['tick_pt']['y']-gen2['height'])]],dtype=np.int32)], typization('axes'))\n",
    "    for i in range(len(axey)):\n",
    "        cv2.fillPoly(creator, [np.array([[(axey[i]['tick_pt']['x'],axey[i]['tick_pt']['y'])],[(axey[i]['tick_pt']['x']+gen2['width'],axey[i]['tick_pt']['y'])]],dtype=np.int32)], typization('axes'))\n",
    "    if len(gen[\"visual-elements\"][\"bars\"])!=0:\n",
    "        for el in gen[\"visual-elements\"][\"bars\"]:\n",
    "            cv2.fillPoly(creator, [np.array([[(el['x0']+el['width'],el['y0'])],[(el['x0'],el['y0'])],[(el['x0'],el['y0']+el['height'])],[(el['x0']+el['width'],el['y0']+el['height'])]],dtype=np.int32)], typization('bars'))\n",
    "    elif len(gen[\"visual-elements\"][\"boxplots\"])!=0:\n",
    "        ...\n",
    "    elif len(gen['visual-elements']['dot points'])!=0:\n",
    "        for i in gen['visual-elements']['dot points'][0]:\n",
    "            cv2.circle(creator, (int(i['x']), int(i['y'])), 4, typization('dot points'), 8)\n",
    "    elif len(gen['visual-elements']['lines'])!=0:\n",
    "        k=[]\n",
    "        for i in gen['visual-elements']['lines'][0]:\n",
    "            cv2.circle(creator, (int(i['x']), int(i['y'])), 2, typization('dot points'), 5)\n",
    "        for i in range(1,len(gen['visual-elements']['lines'][0])):\n",
    "            cv2.drawContours(creator,[np.array([(int(gen['visual-elements']['lines'][0][i-1]['x']),int(gen['visual-elements']['lines'][0][i-1]['y'])),(int(gen['visual-elements']['lines'][0][i]['x']),int(gen['visual-elements']['lines'][0][i]['y']))])],-1,typization('lines'),3)\n",
    "    elif len(gen['visual-elements']['scatter points'])!=0:\n",
    "        for i in gen['visual-elements']['scatter points'][0]:\n",
    "            cv2.circle(creator, (int(i['x']), int(i['y'])), 2, typization('dot points'), 5)\n",
    "#    cv2.imwrite(\"mask.jpg\",creator)\n",
    "#    polygon_detection.script(img_exampl,creator)\n",
    "    creator = cv2.cvtColor(creator, cv2.COLOR_BGR2GRAY)\n",
    "    creator = np.array([creator]*3)\n",
    "    output = torch.from_numpy(creator)\n",
    "    return output\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ee68541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:22:32.367942Z",
     "iopub.status.busy": "2023-05-25T13:22:32.367564Z",
     "iopub.status.idle": "2023-05-25T13:22:32.402622Z",
     "shell.execute_reply": "2023-05-25T13:22:32.401524Z"
    },
    "papermill": {
     "duration": 0.05247,
     "end_time": "2023-05-25T13:22:32.404991",
     "exception": false,
     "start_time": "2023-05-25T13:22:32.352521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reconstruct(img: np.ndarray, mask: np.ndarray, tup: tuple):\n",
    "    if tup == (128, 64, 128): #Chart title\n",
    "        coords = np.where(mask[:,:,] == tup) #Ищем координаты полигона\n",
    "\n",
    "        y_begin, y_end = coords[0].min(), coords[0].max() #Выделяем полигон\n",
    "        x_begin, x_end = coords[1].min(), coords[1].max()\n",
    "\n",
    "        return img[y_begin:y_end, x_begin:x_end] #Возвращаем обрезанное изображение\n",
    "\n",
    "    if tup == (130, 76, 0): #Axis title\n",
    "        coords = np.where(mask[:,:,] == tup) #Ищем координаты полигона\n",
    "        fst_border = [] #Границы y координат\n",
    "        snd_border = [] #Границы х координат\n",
    "\n",
    "        for i in range(len(coords[0])):\n",
    "            if coords[0][i] - coords[0][i + 1] < -1: #Все координаты идут в порядке возрастания, потому мы ищем резкий скачок значения в списке\n",
    "                fst_border.append((coords[0][0], coords[0][i]))\n",
    "                snd_border.append((coords[0][i + 1], coords[0].max()))\n",
    "                break\n",
    "\n",
    "        for i in range(len(coords[1])):\n",
    "            if coords[1][i] - coords[1][i + 1] < -1:\n",
    "                fst_border.append((coords[1][0], coords[1][i]))\n",
    "                snd_border.append((coords[1][i + 1], coords[1].max()))\n",
    "                break\n",
    "\n",
    "        img1 = img[fst_border[0][0]:fst_border[0][1],fst_border[1][0]:fst_border[1][1]]\n",
    "        img2 = img[snd_border[0][0]:snd_border[0][1],snd_border[1][0]:snd_border[1][1]]\n",
    "\n",
    "        return img1, img2\n",
    "\n",
    "    if tup == (0, 102, 0):\n",
    "        coords = np.where(mask[:,:,] == tup) #Ищем координаты полигона\n",
    "        y_tick_borders = []\n",
    "\n",
    "        end_for_y_ticks = 0\n",
    "        for i in range(len(coords[1])):\n",
    "            if coords[1][i] - coords[1][i + 1] > 0:\n",
    "                end_for_y_ticks = coords[1][i]\n",
    "                break\n",
    "\n",
    "        upper_border_y = coords[0][0]\n",
    "        for i in range(len(coords[0])):\n",
    "            try:\n",
    "                if coords[0][i] - coords[0][i + 1] < -1:\n",
    "                    y_tick_borders.append([(upper_border_y, coords[0][i]), (coords[1][0], end_for_y_ticks)])\n",
    "                    upper_border_y = coords[0][i + 1]\n",
    "            except BaseException:\n",
    "                pass\n",
    "\n",
    "        x_tick_border = img[upper_border_y:coords[0].max(), end_for_y_ticks:coords[1].max(),]\n",
    "\n",
    "        return y_tick_borders, x_tick_border\n",
    "\n",
    "    if tup == (112, 103, 87) or tup == (5, 5, 5):\n",
    "        coords = np.where(mask[:,:,] == tup)\n",
    "\n",
    "        y_begin, y_end = coords[0].min(), coords[0].max()\n",
    "        x_begin, x_end = coords[1].min(), coords[1].max()\n",
    "\n",
    "        return img[y_begin:y_end, x_begin:x_end + 1]\n",
    "\n",
    "    if tup == (48, 41, 30):\n",
    "        coords = np.where(mask[:,:,] == tup)\n",
    "        bar_lower_border = np.where(mask[:,:,] == (0, 102, 0))[0].max()\n",
    "        bar_upper_border = coords[0].min()\n",
    "        bar_borders = []\n",
    "\n",
    "        all_bar_polygons = np.unique(coords[1])\n",
    "\n",
    "        left_border = all_bar_polygons[0]\n",
    "        for i in range(len(all_bar_polygons)):\n",
    "            try:\n",
    "                if all_bar_polygons[i] - all_bar_polygons[i + 1] < -1:\n",
    "                    bar_borders.append([(bar_upper_border, bar_lower_border), (left_border, all_bar_polygons[i])])\n",
    "                    left_border = all_bar_polygons[i + 1]\n",
    "            except BaseException:\n",
    "                pass\n",
    "\n",
    "        return bar_borders\n",
    "\n",
    "    coords = np.where(mask[:,:,] == tup)\n",
    "\n",
    "    y_begin, y_end = coords[0].min(), coords[0].max()\n",
    "    x_begin, x_end = coords[1].min(), coords[1].max()\n",
    "\n",
    "    return img[y_begin:y_end, x_begin:x_end + 1]\n",
    "\n",
    "def script(img: np.ndarray, mask: np.ndarray):\n",
    "    typ = {'chart_title': (128, 64, 128),\n",
    "    'axis_title': (130, 76, 0),\n",
    "    'tick_label': (0, 102, 0),\n",
    "    'plot-bb': (112, 103, 87),\n",
    "    'axes': (28, 42, 168),\n",
    "    \"bars\": (48, 41, 30),\n",
    "    \"boxplots\": (0, 50, 89),\n",
    "    \"dot points\": (107, 142, 35),\n",
    "    \"lines\": (70, 70, 70),\n",
    "    \"scatter points\": (102, 102, 156)} #Цвет каждого полигона\n",
    "\n",
    "    #Основной скрипт для восстановки полигонов\n",
    "    ct = reconstruct(img, mask, typ[\"chart_title\"])\n",
    "\n",
    "    at1, at2 = reconstruct(img, mask, typ[\"axis_title\"])\n",
    "#    cv2.imwrite('./results/axis_title_y.jpg', at1)\n",
    "#    cv2.imwrite('./results/axis_title_x.jpg', at2)\n",
    "\n",
    "    tl_y, tl_x = reconstruct(img, mask, typ['tick_label'])\n",
    "    y_tick_fragments = []\n",
    "    for i in range(len(tl_y)):\n",
    "        up, down = tl_y[i][0][0], tl_y[i][0][1]\n",
    "        left, right = tl_y[i][1][0], tl_y[i][1][1]\n",
    "\n",
    "        fragment = img[up:down, left:right,]\n",
    "\n",
    "        y_tick_fragments.append(fragment)\n",
    "    x_tick_fragments = tl_x\n",
    "\n",
    "    pb = reconstruct(img, mask, typ[\"plot-bb\"])\n",
    "\n",
    "    axes = reconstruct(img, mask, typ[\"axes\"])\n",
    "\n",
    "    try:\n",
    "        bars = reconstruct(img, mask, typ['bars'])\n",
    "        bar_fragments = []\n",
    "        for i in range(len(bars)):\n",
    "            up, down = bars[i][0][0], bars[i][0][1]\n",
    "            left, right = bars[i][1][0] - 30, bars[i][1][1]\n",
    "\n",
    "            fragment = img[up:down,left:right,]\n",
    "            bar_fragments.append(fragment)\n",
    "        \n",
    "        return ct, (at1, at2), (y_tick_fragments, x_tick_fragments), pb, axes, bar_fragments, 'bars'\n",
    "    except BaseException:\n",
    "        pass\n",
    "    try:\n",
    "        bp = reconstruct(img, mask, typ[\"boxplots\"])\n",
    "        boxplot_fragments = []\n",
    "        for i in range(len(bp)):\n",
    "            up, down = bars[i][0][0], bars[i][0][1]\n",
    "            left, right = bars[i][1][0] - 30, bars[i][1][1]\n",
    "\n",
    "            fragment = img[up:down,left:right,]\n",
    "            boxplot_fragments.append(fragment)\n",
    "        \n",
    "        return ct, (at1, at2), (y_tick_fragments, x_tick_fragments), pb, axes, boxplot_fragments, 'boxplots'\n",
    "    except BaseException:\n",
    "        pass\n",
    "    try:\n",
    "        dp = reconstruct(img, mask, typ[\"dot points\"])\n",
    "        dp_fragments = []\n",
    "        for i in range(len(dp)):\n",
    "            up, down = bars[i][0][0], bars[i][0][1]\n",
    "            left, right = bars[i][1][0] - 30, bars[i][1][1]\n",
    "\n",
    "            fragment = img[up:down,left:right,]\n",
    "            \n",
    "            dp_fragments.append(fragment)\n",
    "        return ct, (at1, at2), (y_tick_fragments, x_tick_fragments), pb, axes, dp_fragments, 'dot point'\n",
    "    except BaseException:\n",
    "        pass\n",
    "    try:\n",
    "        lines = reconstruct(img, mask, typ[\"lines\"])\n",
    "        line_fragments = []\n",
    "        for i in range(len(lines)):\n",
    "            up, down = bars[i][0][0], bars[i][0][1]\n",
    "            left, right = bars[i][1][0] - 30, bars[i][1][1]\n",
    "\n",
    "            fragment = img[up:down,left:right,]\n",
    "\n",
    "            line_fragments.append(fragment)\n",
    "        return ct, (at1, at2), (y_tick_fragments, x_tick_fragments), pb, axes, line_fragments, 'lines'\n",
    "    except BaseException:\n",
    "        pass\n",
    "    try:\n",
    "        sp = reconstruct(mask, typ['scatter points'])\n",
    "        scatter_fragments = []\n",
    "        for i in range(len(sp)):\n",
    "            up, down = bars[i][0][0], bars[i][0][1]\n",
    "            left, right = bars[i][1][0] - 30, bars[i][1][1]\n",
    "\n",
    "            fragment = img[up:down,left:right,]\n",
    "            scatter_fragments.append(fragment)\n",
    "        return ct, (at1, at2), (y_tick_fragments, x_tick_fragments), pb, axes, scatter_fragments, 'scatter points'\n",
    "    except BaseException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0461ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:22:32.434145Z",
     "iopub.status.busy": "2023-05-25T13:22:32.433779Z",
     "iopub.status.idle": "2023-05-25T13:44:45.417677Z",
     "shell.execute_reply": "2023-05-25T13:44:45.416433Z"
    },
    "papermill": {
     "duration": 1333.001216,
     "end_time": "2023-05-25T13:44:45.419952",
     "exception": false,
     "start_time": "2023-05-25T13:22:32.418736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id data_series    chart_type\n",
      "0  000b92c3b098_x     abc;def  vertical_bar\n",
      "1  000b92c3b098_y     0.0;1.0  vertical_bar\n",
      "2  007a18eb4e09_x     abc;def  vertical_bar\n",
      "3  007a18eb4e09_y     0.0;1.0  vertical_bar\n",
      "4  00dcf883a459_x     abc;def  vertical_bar\n",
      "['bars', 'boxplots', 'dot points', 'lines', 'scatter points']\n",
      "experimental\n",
      "loaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n",
      "100%|██████████| 161M/161M [00:00<00:00, 183MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n"
     ]
    }
   ],
   "source": [
    "image_path = '/kaggle/input/benetech-making-graphs-accessible/train/images'\n",
    "mask_path = '/kaggle/input/benetech-making-graphs-accessible/train/annotations'\n",
    "test_path = '/kaggle/input/benetech-making-graphs-accessible/train/images'\n",
    "labels = pd.read_csv('/kaggle/input/benetech-making-graphs-accessible/sample_submission.csv')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(labels.head())\n",
    "classes = ['bars','boxplots',\"dot points\",\"lines\",\"scatter points\"]#labels.name.values.tolist()\n",
    "print(classes)\n",
    "length = len(os.listdir(image_path))\n",
    "#Тут куча закомментированного, но не удалённого (рудиментарного) кода\n",
    "'''class Graphics(Dataset):\n",
    "    def __init__(self, imgs_dir, masks_dir, count, is_val = False):\n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.masks_dir = masks_dir\n",
    "\n",
    "        imgs_paths = os.listdir(self.imgs_dir)\n",
    "        imgs_paths.sort()\n",
    "\n",
    "        mask_paths = os.listdir(self.masks_dir)\n",
    "        mask_paths.sort()\n",
    "\n",
    "        self.is_val = is_val\n",
    "        if not is_val:  # для разделения на train/val в процессе\n",
    "            self.imgs_paths = imgs_paths[:count]\n",
    "            self.mask_paths = mask_paths[:count]\n",
    "        else:\n",
    "            self.imgs_paths = imgs_paths[-count:]\n",
    "            self.mask_paths = mask_paths[-count:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = read_image(os.path.join(self.imgs_dir, self.imgs_paths[idx]), ImageReadMode.RGB)\n",
    "        mask = interesting(os.path.join(self.masks_dir, self.mask_paths[idx]),img.shape)\n",
    "#        mask = read_image(os.path.join(self.masks_dir, self.mask_paths[idx]), ImageReadMode.GRAY)\n",
    "\n",
    "        return img, mask'''\n",
    "    \n",
    "torchvision.models.segmentation.DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1.transforms()\n",
    "#Функция, предназначенная единственно чтобы изменять размер изображения (само изображение не меняется, т. к. важна точность до пикселя)\n",
    "#def img_transform(img, mask, is_val=False, size=520):\n",
    "#    img = img.float() / 255.0\n",
    "\n",
    "#    one_dim = img.shape[2]\n",
    "#    two_dim = img.shape[3]\n",
    "#    one_dim1 = mask.shape[2]\n",
    "#    two_dim1 = mask.shape[3]\n",
    "\n",
    "#    dim1 = torch.Tensor([[(4096-one_dim)*[[0]]]]*3)\n",
    "#    dim2 = torch.Tensor([[[(4096-two_dim)*[0]]]]*3)\n",
    "#    dim3 = torch.Tensor([[(4096-one_dim1)*[[0]]]]*3)\n",
    "#    dim4 = torch.Tensor([[[(4096-two_dim1)*[0]]]]*3)\n",
    "#    dim1 = torch.Tensor([[(4096-one_dim)*[0]]]).unsqueeze(0).unsqueeze(0)\n",
    "#    dim2 = torch.Tensor([[[(4096-two_dim)*[0]]]]).unsqueeze(0).unsqueeze(0)\n",
    "#    dim3 = torch.Tensor([[(4096-one_dim1)*[0]]]).unsqueeze(0).unsqueeze(0)\n",
    "#    dim4 = torch.Tensor([[[(4096-two_dim1)*[0]]]]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "#    img = torch.cat((torch.cat((img,dim1),dim=2),dim2),dim=3)\n",
    "#    mask = torch.cat((torch.cat((mask,dim3),dim=2),dim4),dim=3)\n",
    "#    img = img.to(device)\n",
    "\n",
    "#    mask = mask.to(device)\n",
    "\n",
    "#    return img, mask.squeeze(1).long()\n",
    "def img_transform(img, mask, is_val=False, size=520):\n",
    "    img = img.float() / 255.0\n",
    "    mask = mask.float() / 255.0\n",
    "\n",
    "    one_dim = img.shape[2]\n",
    "    two_dim = img.shape[3]\n",
    "    one_dim1 = mask.shape[2]\n",
    "    two_dim1 = mask.shape[3]\n",
    "\n",
    "    dim1 = torch.zeros((img.shape[0], img.shape[1], 1024 - one_dim, img.shape[3]))\n",
    "    dim2 = torch.zeros((img.shape[0], img.shape[1], 1024, 1024 - two_dim))\n",
    "    dim3 = torch.zeros((mask.shape[0], mask.shape[1], 1024 - one_dim1, mask.shape[3]))\n",
    "    dim4 = torch.zeros((mask.shape[0], mask.shape[1], 1024, 1024 - two_dim1))\n",
    "\n",
    "    img = torch.cat((torch.cat((img,dim1),dim=2),dim2),dim=3)\n",
    "    mask = torch.cat((torch.cat((mask,dim3),dim=2),dim4),dim=3) # fixed dimension here\n",
    "    img = img.to(device)\n",
    "\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    return img, mask.squeeze(2).long()\n",
    "\n",
    "img = torch.randn(2, 3, 100, 50)\n",
    "mask = torch.randn(2, 3, 80, 70)\n",
    "\n",
    "img_resized, mask_resized = img_transform(img, mask)\n",
    "\n",
    "train_dataset_len = int(length * 0.7)\n",
    "val_dataset_len = length - train_dataset_len\n",
    "\n",
    "#train_dataset = Graphics(image_path, mask_path, train_dataset_len)\n",
    "\n",
    "#val_dataset = Graphics(image_path, mask_path, val_dataset_len, is_val=True)\n",
    "\n",
    "#print(train_dataset[5][0].shape)\n",
    "#print(train_dataset[5][1].shape)\n",
    "#img, mask = next(iter(train_dataset))\n",
    "\n",
    "batch_size = 2\n",
    "#Класс датасета, ещё не реализовал всё, что хотел\n",
    "class ExperimentalDataset:\n",
    "    def __init__(self,img_dir,mask_dir,batch,train='train'):\n",
    "        self.newlist = []\n",
    "        self.batch_size=batch\n",
    "        k=0\n",
    "#        print(os.listdir(img_dir))\n",
    "#        idl=list(os.listdir(img_dir).sort())\n",
    "#        mdl=list(os.listdir(mask_dir).sort())\n",
    "#        for i in range(10):\n",
    "#            print(idl[i],mdl[i])\n",
    "#        ls = list(zip(idl,mdl))\n",
    "        if train=='train':\n",
    "#            self.newlist=ls[:int(0.9*len(ls))]\n",
    "            for i in range(int(len(os.listdir(img_dir))*0.9)):   #os.listdir(img_dir)[:int(len(os.listdir(img_dir))*0.9)]\n",
    "                namef = os.listdir(img_dir)[i]\n",
    "                self.newlist.append((img_dir+'/'+namef,mask_dir+'/'+namef[:-4]+'.json'))\n",
    "        elif train=='validation':\n",
    "#            self.newlist=ls[:int(0.9*len(ls))]\n",
    "            for i in range(int(len(os.listdir(img_dir))*0.1)):   #os.listdir(img_dir)[int(len(os.listdir(img_dir))*0.1):]\n",
    "                namef = os.listdir(img_dir)[int(len(os.listdir(img_dir))*0.9)+i]\n",
    "                self.newlist.append((img_dir+'/'+namef,mask_dir+'/'+namef[:-4]+'.json'))\n",
    "        else:\n",
    "#            self.newlist=ls\n",
    "            for i in range((len(os.listdir(img_dir)))):\n",
    "                self.newlist.append((os.listdir(img_dir)[i],os.listdir(mask_dir)[i]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.newlist)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img=[]\n",
    "        mask=[]\n",
    "        transforming = transforms.ColorJitter(brightness=0.4,contrast=0.4)\n",
    "        img.append(read_image(self.newlist[index+1][0]))\n",
    "        mask.append(interesting(self.newlist[index][1],img[0].shape))\n",
    "        for i in range(self.batch_size):\n",
    "            mask.append(mask[0])\n",
    "            img.append(transforming(img[0]))\n",
    "        return (torch.stack(img,dim=0),torch.stack(mask,dim=0))\n",
    "print('experimental')\n",
    "#train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=2)\n",
    "train_loader = ExperimentalDataset(img_dir=image_path,mask_dir=mask_path,batch=batch_size,train='train')\n",
    "print('loaders')\n",
    "#val_loader = DataLoader(val_dataset, batch_size, shuffle=False, num_workers=2)\n",
    "val_loader = ExperimentalDataset(img_dir=image_path,mask_dir=mask_path,batch=batch_size,train='validation')\n",
    "#Модель для сегментации (вскоре будет изменена)\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet50(weights=torchvision.models.segmentation.DeepLabV3_ResNet50_Weights.DEFAULT,\n",
    "                                                    progress=True)\n",
    "print('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a2113d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:44:45.451262Z",
     "iopub.status.busy": "2023-05-25T13:44:45.450223Z",
     "iopub.status.idle": "2023-05-25T13:44:45.626890Z",
     "shell.execute_reply": "2023-05-25T13:44:45.626003Z"
    },
    "papermill": {
     "duration": 0.194662,
     "end_time": "2023-05-25T13:44:45.629188",
     "exception": false,
     "start_time": "2023-05-25T13:44:45.434526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision.models.segmentation.fcn import FCNHead\n",
    "model.classifier = DeepLabHead(2048, 23)\n",
    "model.aux_classifier = FCNHead(1024, 23)\n",
    "model = model.to(device)\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "#Функция ошибки, оптимизатор\n",
    "loss = CrossEntropyLoss()#.to(device)\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9322cc42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:44:45.660670Z",
     "iopub.status.busy": "2023-05-25T13:44:45.659767Z",
     "iopub.status.idle": "2023-05-25T13:44:45.665878Z",
     "shell.execute_reply": "2023-05-25T13:44:45.664906Z"
    },
    "papermill": {
     "duration": 0.023905,
     "end_time": "2023-05-25T13:44:45.667924",
     "exception": false,
     "start_time": "2023-05-25T13:44:45.644019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pixel_accuracy(mask, output):\n",
    "    output_softmax = F.softmax(output, dim=1)\n",
    "    output_argmax = torch.argmax(output_softmax, dim=1)\n",
    "#softmax(zi) = exp(zi)/sum[k:1..K](exp(zk))\n",
    "#Свойства softmaxя\n",
    "    bool_tensor = (torch.flatten(mask)) == (torch.flatten(output_argmax))\n",
    "\n",
    "    return torch.sum(bool_tensor) / torch.numel(bool_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e330e4d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T13:44:45.699277Z",
     "iopub.status.busy": "2023-05-25T13:44:45.698889Z",
     "iopub.status.idle": "2023-05-25T13:44:46.041566Z",
     "shell.execute_reply": "2023-05-25T13:44:46.040080Z"
    },
    "papermill": {
     "duration": 0.360876,
     "end_time": "2023-05-25T13:44:46.043720",
     "exception": true,
     "start_time": "2023-05-25T13:44:45.682844",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54520\n",
      "6057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54520 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img:  torch.Size([3, 480, 640]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     train_pixel_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     27\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l,(img_batch, mask_batch) \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#        print(epoch)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         img_batch, mask_batch \u001b[38;5;241m=\u001b[39m img_transform(img_batch, mask_batch, is_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#        img_batch = img_batch.to(device, non_blocking=True)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#        mask_batch = mask_batch.to(device, non_blocking=True)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epoch_count = 30\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "es_steps = 3\n",
    "count_steps = 0\n",
    "\n",
    "train_len = len(train_loader)\n",
    "val_len = len(val_loader)\n",
    "print(train_len)\n",
    "print(val_len)\n",
    "\n",
    "best_score = 1e10\n",
    "#Обучение и валидация (надеюсь, не нужно описывать всё, что здесь происходит)\n",
    "for epoch in range(epoch_count):\n",
    "    if count_steps >= es_steps:\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "\n",
    "    train_loss_sum = 0\n",
    "    train_pixel_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    for l,(img_batch, mask_batch) in tqdm(train_loader):\n",
    "#        print(epoch)\n",
    "        img_batch, mask_batch = img_transform(img_batch, mask_batch, is_val=False)\n",
    "#        img_batch = img_batch.to(device, non_blocking=True)\n",
    "#        mask_batch = mask_batch.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_batch = model(img_batch)\n",
    "        loss_value = loss(output_batch['out'], mask_batch)\n",
    "\n",
    "        train_pixel_acc += pixel_accuracy(mask_batch, output_batch['out']).detach()\n",
    "        train_loss_sum += loss_value.detach()\n",
    "\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        del output_batch\n",
    "\n",
    "    train_loss = train_loss_sum / train_len\n",
    "    train_acc = train_pixel_acc / train_len\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch} / {epoch_count} | train loss = {train_loss} | train acc = {train_acc}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_loss_sum = 0\n",
    "    val_pixel_acc = 0\n",
    "\n",
    "    for img_batch, mask_batch in (val_loader):\n",
    "        img_batch, mask_batch = img_transform(img_batch, mask_batch, is_val=True)\n",
    "#        img_batch = img_batch.to(device, non_blocking=True)\n",
    "#        mask_batch = mask_batch.to(device, non_blocking=True)\n",
    "\n",
    "        output_batch = model(img_batch)\n",
    "        loss_value = loss(output_batch['out'], mask_batch)\n",
    "\n",
    "        val_loss_sum = val_loss_sum + loss_value.detach()\n",
    "        val_pixel_acc = val_pixel_acc + pixel_accuracy(mask_batch, output_batch['out']).detach()\n",
    "        \n",
    "        del output_batch\n",
    "\n",
    "    val_loss = val_loss_sum / val_len\n",
    "    val_acc = val_pixel_acc / val_len\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    print(f\"Epoch {epoch} / {epoch_count} | val loss = {val_loss} | val acc = {val_acc}\")\n",
    "\n",
    "    if val_loss < best_score:\n",
    "        best_score = val_loss\n",
    "        count_steps = 0\n",
    "        torch.save(model, \"best_model1.pt\")\n",
    "    else:\n",
    "        count_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09597c35",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_losses = [x.cpu().item() for x in train_losses]\n",
    "val_losses = [x.cpu().item() for x in val_losses]\n",
    "plt.plot(train_losses, linestyle=\"-\")\n",
    "plt.plot(val_losses, linestyle=\"--\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d1f4f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_accs = [x.cpu().item() for x in train_accs]\n",
    "val_accs = [x.cpu().item() for x in val_accs]\n",
    "\n",
    "plt.plot(train_accs, linestyle=\"-\")\n",
    "plt.plot(val_accs, linestyle=\"--\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d43d4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "label_map = np.array([\n",
    "    (0, 0, 0),  # unlabeled\n",
    "    (128, 64, 128),  # chart_title\n",
    "    (130, 76, 0),  # axis_title\n",
    "    (0, 102, 0),  # tick_label\n",
    "    (112, 103, 87),  # plot-bb\n",
    "    (28, 42, 168),  # axes\n",
    "    (48, 41, 30),  # bars\n",
    "    (0, 50, 89), # boxplots\n",
    "    (107, 142, 35),  # dot points\n",
    "    (70, 70, 70),  # lines\n",
    "    (102, 102, 156),  # scatter points\n",
    "    (255, 0, 0), # conflicting\n",
    "])\n",
    "\n",
    "def draw_segmentation_map(outputs):\n",
    "    labels = torch.argmax(outputs.squeeze(), dim=0).numpy()\n",
    "  \n",
    "    # Create 3 Numpy arrays containing zeros.\n",
    "    # Later each pixel will be filled with respective red, green, and blue pixels\n",
    "    # depending on the predicted class.\n",
    "  \n",
    "    red_map   = np.zeros_like(labels).astype(np.uint8)\n",
    "    green_map = np.zeros_like(labels).astype(np.uint8)\n",
    "    blue_map  = np.zeros_like(labels).astype(np.uint8)\n",
    "  \n",
    "    for label_num in range(0, len(label_map)):\n",
    "        index = labels == label_num\n",
    "         \n",
    "        R, G, B = label_map[label_num]\n",
    "  \n",
    "        red_map[index]   = R\n",
    "        green_map[index] = G\n",
    "        blue_map[index]  = B\n",
    "  \n",
    "    segmentation_map = np.stack([red_map, green_map, blue_map], axis=2)\n",
    "    return segmentation_map\n",
    "\n",
    "def image_overlay(image, segmented_image):\n",
    "    alpha = 1  # transparency for the original image\n",
    "    beta  = 0.8  # transparency for the segmentation map\n",
    "    gamma = 0  # scalar added to each sum\n",
    "  \n",
    "    image = np.array(image)\n",
    "    segmented_image = cv2.cvtColor(segmented_image, cv2.COLOR_RGB2BGR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "     \n",
    "    cv2.addWeighted(image, alpha, segmented_image, beta, gamma, image)\n",
    "  \n",
    "    return image\n",
    "\n",
    "imgs_paths = os.listdir(image_path)\n",
    "imgs_paths.sort()\n",
    "\n",
    "def perform_inference(model=model ,imgs_paths=imgs_paths, num_images=10, image_dir='/kaggle/input/benetech-making-graphs-accessible/train/images/', device='cpu'):\n",
    "     \n",
    "#    out_table = pd.DataFrame(np.array([np.array(['nothing','nothing','nothing'])]),columns=['id','data_series','chart_type'])\n",
    "     \n",
    "    device = device if device is not None else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    tdb = []\n",
    "\n",
    "    model.to(device)\n",
    "    #preprocess = transforms.Compose([\n",
    "    #  transforms.Resize([520, 520]),\n",
    "    #  transforms.ToTensor(),\n",
    "    #  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    #])\n",
    "    # Load image handles for the validation set.\n",
    "  \n",
    "    # Randomly select 'num_images' from the whole set for inference.\n",
    "    selected_images = imgs_paths\n",
    "  \n",
    "    # Iterate over selected images\n",
    "    for img_name in selected_images:\n",
    "         \n",
    "        # Load and pre-process image.\n",
    "        xsdb = [img_name[-4:]+'_x',\"\",\"\"]\n",
    "        ysdb = [img_name[-4:]+'_y',\"\",\"\"]\n",
    "        image_path = os.path.join(image_dir, img_name)\n",
    "        img_raw = Image.open(image_path).convert(\"RGB\")\n",
    "        W, H = img_raw.size[:2]\n",
    "        img_t = img_transform(img_raw)\n",
    "        img_t = torch.unsqueeze(img_t, dim=0).to(device)\n",
    "  \n",
    "        # Model Inference\n",
    "        with torch.no_grad():\n",
    "            output = model(img_t)[\"out\"].cpu()\n",
    "  \n",
    "        # Get RGB segmentation map\n",
    "        segmented_image = draw_segmentation_map(output)\n",
    "        ct, (at1, at2), (y_tick_fragments, x_tick_fragments), pb, axes, boxplot_fragments typeOf = script(img_t,segmented_image)\n",
    "        \n",
    "        xsdb[2]=typeOf\n",
    "        ysdb[2]=typeOf\n",
    "        \n",
    "        xsdb[1]=';'.join([mmocr.models.textrecog.recognize(k) for k in x_tick_fragments])\n",
    "        ysdb[1]=';'.join([mmocr.models.textrecog.recognize(k) for k in y_tick_fragments])\n",
    "        \n",
    "        # Resize to original image size\n",
    "        segmented_image = cv2.resize(segmented_image, (W, H), cv2.INTER_LINEAR)\n",
    "        overlayed_image = image_overlay(img_raw, segmented_image)\n",
    "        \n",
    "        tdb.append(np.array(xsdb))\n",
    "        tdb.append(np.array(ysdb))\n",
    "         \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 10), dpi=100)\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Image\")\n",
    "        plt.imshow(np.asarray(img_raw))\n",
    "  \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(\"Segmentation\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(segmented_image)\n",
    "  \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"Overlayed\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(overlayed_image[:, :, ::-1])\n",
    "         \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "  \n",
    "    return np.array(tdb)\n",
    "\n",
    "table_db=perform_inference()\n",
    "table_db=pd.DataFrame(table_db)\n",
    "table_db.to_csv('/kaggle/output/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c557071",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''import torch\n",
    "import torchvision as tv\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def vertical_steps(arr: np.ndarray, flag_arr: np.ndarray, x, y):\n",
    "    y_end = 0\n",
    "    steps_spent = 0\n",
    "\n",
    "    while arr[x][y + steps_spent] == [0, 255, 13]:\n",
    "        flag_arr[x][y + steps_spent] = True\n",
    "        steps_spent += 1\n",
    "\n",
    "    y_end = y + steps_spent\n",
    "    \n",
    "    return [x, y_end], steps_spent, flag_arr\n",
    "\n",
    "def horizontal_steps(arr: np.ndarray, flag_arr: np.ndarray, x, y):\n",
    "    x_end = 0\n",
    "    steps_spent = 0\n",
    "\n",
    "    while arr[x + steps_spent][y] == [0, 255, 13]:\n",
    "        flag_arr[x + steps_spent][y] = True\n",
    "        steps_spent += 1\n",
    "\n",
    "    x_end = x + steps_spent\n",
    "\n",
    "    return [x_end, y], steps_spent, flag_arr\n",
    "\n",
    "def script(tensor: np.ndarray):\n",
    "    tensor_shape = np.shape(tensor)\n",
    "    tensor_shape = (tensor_shape[0], tensor_shape[1], 1)\n",
    "    flag_arr = np.zeros(tensor_shape)\n",
    "    final_tensors = []\n",
    "\n",
    "    for i in range(len(tensor)):\n",
    "        for j in range(len(tensor[i])):\n",
    "            if tensor[i][j] == [0, 255, 13] and not flag_arr[i][j]:\n",
    "                a = (i, j)\n",
    "                b, b_steps, flag_arr = horizontal_steps(tensor, flag_arr, i, j)\n",
    "                c, c_steps, flag_arr = vertical_steps(tensor, flag_arr, i, j)\n",
    "\n",
    "                if b_steps < c_steps:\n",
    "                    d, _, flag_arr = vertical_steps(tensor, b[0], b[1])\n",
    "                else:\n",
    "                    d, _, flag_arr = horizontal_steps(tensor, c[0], c[1])\n",
    "\n",
    "                final_tensor = tensor[b[1]:c[1], a[0]:d[0]]\n",
    "                final_tensors.append(final_tensor)\n",
    "\n",
    "    return final_tensors\n",
    "\n",
    "arr = np.random.randint(0, 255, size=(90,90,3))\n",
    "script(arr)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1761.420688,
   "end_time": "2023-05-25T13:44:48.868593",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-25T13:15:27.447905",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
